{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qqq transformers datasets bitsandbytes accelerate scikit-learn peft trl","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\nfrom datasets import load_dataset\nimport numpy as np\n\nTOKEN = \"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\"\nMODEL_NAME = \"google/gemma-7b\"\ndevice = \"cuda\"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=TOKEN)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME, quantization_config=bnb_config, device_map=\"auto\", token=TOKEN)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load IMDB dataset and extract 300 rows\ndataset = load_dataset('imdb')\n\ntrain_ds = dataset['train'].select(range(300))\ntest_ds = dataset['test'].shuffle(seed=42).select(range(300))\n\n# Check for NaN or Inf values in the dataset\ntrain_ds = train_ds.filter(lambda x: not any(pd.isna(v) or pd.isinf(v) for v in x.values()))\ntest_ds = test_ds.filter(lambda x: not any(pd.isna(v) or pd.isinf(v) for v in x.values()))\n\n# Proceed with training or evaluation\nprint(train_ds)\nprint(test_ds)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TOKENS = {\n    \" Positive\": 40695,\n    \" Negative\": 48314,\n    \" positive\": 6222,\n    \" negative\": 8322,\n    \"Positive\": 35202,\n    \"Negative\": 39654,\n}\n\ndef get_prompt_list(item):\n    res = []\n    for text, label in zip(item['text'], item['label']):\n        content = get_prompt(text)\n        content += \"Positive\" if label == 1 else 'Negative'\n        res.append(content)\n    # print(res)\n    return res\n\ndef get_prompt(query):\n    content = f\"\"\"### REVIEW:\n{query}\n\n### SENTIMENT:\n\"\"\"\n    return content\n\ndef llm(query):\n    prompt = get_prompt(query)\n    inputs = tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\")\n    outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=1, output_scores=True, return_dict_in_generate=True)\n\n    positive_pred = outputs.scores[0][0][TOKENS['Positive']]\n    negative_pred = outputs.scores[0][0][TOKENS['Negative']]\n\n    positive_pred = positive_pred.cpu()\n    negative_pred = negative_pred.cpu()\n\n    scores = np.array([positive_pred, negative_pred])\n    probs = np.exp(scores) / np.sum(np.exp(scores))\n    \n    positive_prob = probs[0]\n    negative_prob = probs[1]\n    # print(positive_pred, negative_pred)\n    \n    return tokenizer.decode(outputs.sequences[0]), positive_prob\n\ndef predict(query, print_res = False):\n    text, prob = llm(query)\n    if print_res:\n        print(text)\n    return prob","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\n\ndef print_metrics(y_true, y_pred):\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    \n    print(\"Accuracy:\", accuracy)\n    print(\"Precision:\", precision)\n    print(\"Recall:\", recall)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\ny_pred = []\ny_test = []\ni = 0\nfor ex in tqdm(test_ds):\n    pred, label = predict(ex['text']), ex['label']\n    # print(pred, label)\n    y_pred.append(pred)\n    y_test.append(label)\n\nprint('before fine tuning')\nprint_metrics(y_test, np.round(y_pred))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nfrom peft import LoraConfig\n\nlora_config = LoraConfig(\n    r=8,\n    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    task_type=\"CAUSAL_LM\",\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nfrom trl import SFTTrainer\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_ds,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=4,\n        warmup_steps=2,\n        learning_rate=2e-5,\n        num_train_epochs=2,\n        fp16=True,\n        logging_steps=20,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\",\n        report_to=\"none\"\n    ),\n    peft_config=lora_config,\n    formatting_func=get_prompt_list,\n)\n\ntrainer.train()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# this is very slow if you want to run on all 25k samples :)\n\nfrom tqdm import tqdm\n\ny_pred = []\ny_test = []\ni = 0\nfor ex in tqdm(test_ds):\n    pred, label = predict(ex['text']), ex['label']\n    y_pred.append(pred)\n    y_test.append(label)\n\nprint('after fine tuning')\nprint_metrics(y_test, np.round(y_pred))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnt = 0\nfor i in range(len(y_pred)):\n    if np.round(y_pred[i]) != y_test[i]:\n        example = test_ds[i]\n        print(predict(example['text'], print_res=True), example['label'])\n        cnt += 1\n        if cnt == 5:\n            break","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}