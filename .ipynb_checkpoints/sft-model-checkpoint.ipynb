{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0fa8127b-92f6-419d-a191-c3ef5a3437c8","cell_type":"code","source":" ! pip install -U bitsandbytes accelerate transformers datasets trl peft evaluate rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:20:03.482011Z","iopub.execute_input":"2024-11-07T12:20:03.482429Z","iopub.status.idle":"2024-11-07T12:20:37.743446Z","shell.execute_reply.started":"2024-11-07T12:20:03.482389Z","shell.execute_reply":"2024-11-07T12:20:37.742288Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nCollecting datasets\n  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\nCollecting trl\n  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\nCollecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.12.0-py3-none-any.whl (310 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d29739c4e70ba331e6d5a6512c229f431fbe0ff954bf3bd2dde6b0841ed808b2\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, bitsandbytes, accelerate, transformers, datasets, trl, peft, evaluate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.0.1\n    Uninstalling datasets-3.0.1:\n      Successfully uninstalled datasets-3.0.1\nSuccessfully installed accelerate-1.1.1 bitsandbytes-0.44.1 datasets-3.1.0 evaluate-0.4.3 peft-0.13.2 rouge_score-0.1.2 transformers-4.46.2 trl-0.12.0\n","output_type":"stream"}],"execution_count":1},{"id":"620109eb-cf11-4114-a94f-2b73badb1558","cell_type":"code","source":"from transformers import (\n\n    AutoModelForCausalLM,\n\n    AutoModelForSequenceClassification,\n\n    AutoTokenizer,\n\n    BitsAndBytesConfig,\n\n    DistilBertTokenizer,\n\n    TrainingArguments,\n\n    pipeline,\n\n)\n\nimport evaluate\n\nfrom datasets import load_dataset, Dataset\n\nfrom trl import (\n\n    SFTTrainer,\n\n    PPOTrainer,\n\n    RewardTrainer,\n\n    PPOConfig,\n\n    RewardConfig,\n\n    AutoModelForCausalLMWithValueHead,\n\n)\n\nfrom peft import LoraConfig, get_peft_model\n\nfrom bitsandbytes.optim import AdamW8bit\n\nfrom tqdm import tqdm\n\nimport torch\n\nfrom torch.utils.data import DataLoader, Dataset as torchDataset\n\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:20:37.745452Z","iopub.execute_input":"2024-11-07T12:20:37.745810Z","iopub.status.idle":"2024-11-07T12:20:58.578267Z","shell.execute_reply.started":"2024-11-07T12:20:37.745771Z","shell.execute_reply":"2024-11-07T12:20:58.577449Z"}},"outputs":[],"execution_count":2},{"id":"15447410-a044-42cb-9579-ce07076c1a91","cell_type":"markdown","source":"# Hugging face login","metadata":{}},{"id":"f1177980-1792-44d3-96b7-370e6e1fbdfb","cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token='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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:20:58.579355Z","iopub.execute_input":"2024-11-07T12:20:58.579660Z","iopub.status.idle":"2024-11-07T12:20:58.774741Z","shell.execute_reply.started":"2024-11-07T12:20:58.579627Z","shell.execute_reply":"2024-11-07T12:20:58.773833Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":3},{"id":"b6bcc2df-99ae-46d8-b033-956f8862ce3e","cell_type":"markdown","source":"# Hyperparameter","metadata":{}},{"id":"7e2dba7a-a06e-427d-a5cc-f296c79d32a2","cell_type":"code","source":"dataset = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n\nbase_reward_model_checkpoint = \"google/gemma-2-2b\"\n\nreward_model_repo_name=\"reward_model\"\n\nreward_model_checkpoint=f\"JaishreeramCoder/{reward_model_repo_name}\"\n\noutput_dir=\"/content/sample_data\"\n\nbase_sft_model_checkpoint = \"meta-llama/Llama-3.1-8B\"\n\nsft_model_repo_name = \"sft_model\"\n\nsft_model_checkpoint=f\"JaishreeramCoder/{sft_model_repo_name}\"\n\nrlhf_model_repo_name=\"ppo_gpt2_summary\"\n\nrlhf_model_checkpoint=f\"JaishreeramCoder/{rlhf_model_repo_name}\"\n\nnum_train_epochs_reward_model = 5\n\nnum_train_epochs_sft = 5\n\nnum_train_epochs_ppo_outer=5\n\nppo_training_batch_size=8\n\neval_batch_size = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:20:58.777179Z","iopub.execute_input":"2024-11-07T12:20:58.777752Z","iopub.status.idle":"2024-11-07T12:21:03.217974Z","shell.execute_reply.started":"2024-11-07T12:20:58.777706Z","shell.execute_reply":"2024-11-07T12:21:03.217202Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5d61ee16fca43fa8f21d2f6a1c9f5c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"summarize_from_feedback.py:   0%|          | 0.00/9.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f394510f0c4e07b17805fe0713a50b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/21.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb7066a16fc247b5ba022b09a42f9a32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/22.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9876c6a15b6a4ec1b843b2cc9bf88ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/92858 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b3975b23b24ccc8d5e2390c8570fa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/86086 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca8f738046547baa388d410d392e7ae"}},"metadata":{}}],"execution_count":4},{"id":"9f673700-7ee2-478b-8baa-1bcd400bc736","cell_type":"code","source":"def count_parameters(model):\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return total_params, trainable_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:34:18.504105Z","iopub.execute_input":"2024-11-07T12:34:18.504501Z","iopub.status.idle":"2024-11-07T12:34:18.509894Z","shell.execute_reply.started":"2024-11-07T12:34:18.504468Z","shell.execute_reply":"2024-11-07T12:34:18.508844Z"}},"outputs":[],"execution_count":12},{"id":"a8225f80-adc8-4805-96be-39d096622a73","cell_type":"markdown","source":"# Supervised fine tuned model","metadata":{}},{"id":"dbff2eca-e213-4804-b103-97d7804127bf","cell_type":"code","source":"sft_tokenizer = AutoTokenizer.from_pretrained(base_sft_model_checkpoint)\n\nsft_tokenizer.pad_token = sft_tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:21:03.219271Z","iopub.execute_input":"2024-11-07T12:21:03.219612Z","iopub.status.idle":"2024-11-07T12:21:04.875908Z","shell.execute_reply.started":"2024-11-07T12:21:03.219578Z","shell.execute_reply":"2024-11-07T12:21:04.875013Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110c8d102d7d4c069842bd63f0671108"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18301426ddaf4a4ba096fd082585250c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bcae463d52448748827c630a0475cc7"}},"metadata":{}}],"execution_count":5},{"id":"21f4ec7d-c0b6-43ab-ab06-8d87f57da3c3","cell_type":"code","source":"def get_sft_dataset(data):\n\n    input_ids, attention_mask, label_ids = ([], [], [])\n\n    for i in range(len(data[\"choice\"])):\n\n        input = f\"Summarize the following text:\\n\\n{data['info'][i]['post']}\"\n\n        cur = sft_tokenizer(\n\n            input,\n\n            padding=\"max_length\",\n\n            truncation=True,\n\n            max_length=512,\n\n            padding_side=\"left\",\n\n        )\n\n        cur_input_ids = cur.input_ids\n\n        cur_attention_mask = cur.attention_mask\n\n        completion = (\n\n            data[\"summaries\"][i][1][\"text\"]\n\n            if data[\"choice\"][i] == 1\n\n            else data[\"summaries\"][i][0][\"text\"]\n\n        )\n\n        cur_label_ids = sft_tokenizer(\n\n            completion,\n\n            padding=\"max_length\",\n\n            truncation=True,\n\n            max_length=512,\n\n            padding_side=\"left\",\n\n        ).input_ids\n\n        input_ids.append(cur_input_ids)\n\n        attention_mask.append(cur_attention_mask)\n\n        label_ids.append(cur_label_ids)\n\n\n\n    output = {\n\n        \"input_ids\": input_ids,\n\n        \"attention_masks\": attention_mask,\n\n        \"labels\": label_ids,\n\n    }\n\n    output = Dataset.from_dict(output)\n\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:21:04.876996Z","iopub.execute_input":"2024-11-07T12:21:04.877308Z","iopub.status.idle":"2024-11-07T12:21:04.886242Z","shell.execute_reply.started":"2024-11-07T12:21:04.877275Z","shell.execute_reply":"2024-11-07T12:21:04.885236Z"}},"outputs":[],"execution_count":6},{"id":"9d959b81-f560-4c29-a3da-7322a6d853bb","cell_type":"code","source":"sft_train_dataset = get_sft_dataset(dataset[\"train\"][1000:2000])\n\nsft_eval_dataset = get_sft_dataset(dataset[\"validation\"][1000:2000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:21:04.887291Z","iopub.execute_input":"2024-11-07T12:21:04.887552Z","iopub.status.idle":"2024-11-07T12:21:07.943538Z","shell.execute_reply.started":"2024-11-07T12:21:04.887522Z","shell.execute_reply":"2024-11-07T12:21:07.942742Z"}},"outputs":[],"execution_count":7},{"id":"68f9db73-29bb-4a4c-8c08-39bf22692579","cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\n\n\nquantization_config = BitsAndBytesConfig(\n\n    load_in_4bit=True,\n\n    bnb_4bit_quant_type=\"nf4\",\n\n    bnb_4bit_compute_dtype=compute_dtype,\n\n    bnb_4bit_use_double_quant=False,\n\n)\n\nsft_model = AutoModelForCausalLM.from_pretrained(\n\n    base_sft_model_checkpoint,\n\n    quantization_config=quantization_config,\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:21:08.220501Z","iopub.execute_input":"2024-11-07T12:21:08.220774Z","iopub.status.idle":"2024-11-07T12:28:54.171737Z","shell.execute_reply.started":"2024-11-07T12:21:08.220743Z","shell.execute_reply":"2024-11-07T12:28:54.170675Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f7b331369d4eb89253c06ae2100334"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c9ea0a44a17402da413fee72995ca09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a451c1e7cff4a4fbe63dcd3af2f2b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9227b349d54ad38958533593826ad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daebd679028b4bc588c50afd47bdd958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ee0cae70ab34a65adfdd1e3fb2d1033"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c2809d5b10405399b9194d4aea6548"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c1f6c56619c49a6adaefb4d535b0c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea88cb2a8294f0d9bd7917fd087c68c"}},"metadata":{}}],"execution_count":8},{"id":"44dafc4d-21dd-46f4-8fde-27e130659a6b","cell_type":"code","source":"lora_config =  LoraConfig(\n\n    lora_alpha=16,\n\n    lora_dropout=0.1,\n\n    r=64,\n\n    bias=\"none\",\n\n    task_type=\"CAUSAL_LM\",\n\n)\n\nsft_model = get_peft_model(sft_model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:28:54.291129Z","iopub.execute_input":"2024-11-07T12:28:54.291472Z","iopub.status.idle":"2024-11-07T12:28:54.755428Z","shell.execute_reply.started":"2024-11-07T12:28:54.291429Z","shell.execute_reply":"2024-11-07T12:28:54.754403Z"}},"outputs":[],"execution_count":9},{"id":"8d6e4a40-0ccc-46e6-8498-06b4c7c4d69c","cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:28:54.756902Z","iopub.execute_input":"2024-11-07T12:28:54.757505Z","iopub.status.idle":"2024-11-07T12:28:55.878894Z","shell.execute_reply.started":"2024-11-07T12:28:54.757460Z","shell.execute_reply":"2024-11-07T12:28:55.877750Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Thu Nov  7 12:28:55 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0             31W /  250W |    6265MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":10},{"id":"43159657-c803-4b4b-b4d6-e3f1f480234b","cell_type":"code","source":"print(count_parameters(sft_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:34:28.030564Z","iopub.execute_input":"2024-11-07T12:34:28.030929Z","iopub.status.idle":"2024-11-07T12:34:28.045282Z","shell.execute_reply.started":"2024-11-07T12:34:28.030897Z","shell.execute_reply":"2024-11-07T12:34:28.044386Z"}},"outputs":[{"name":"stdout","text":"(4567863296, 27262976)\n","output_type":"stream"}],"execution_count":13},{"id":"6514baa0-9f39-454b-a350-2aed0ecb7d63","cell_type":"code","source":"sft_training_args = TrainingArguments(\n\n    per_device_train_batch_size=1,\n\n    gradient_accumulation_steps=8,\n\n    optim=\"paged_adamw_32bit\",\n\n    logging_steps=1,\n\n    learning_rate=1e-4,\n\n    fp16=True,\n\n    max_grad_norm=0.3,\n\n    num_train_epochs=num_train_epochs_sft,\n\n    evaluation_strategy=\"epoch\",\n\n    eval_steps=0.2,\n\n    warmup_ratio=0.05,\n\n    save_strategy=\"epoch\",\n\n    group_by_length=True,\n\n    output_dir=\"/content/sample_data\",\n\n    save_safetensors=True,\n\n    lr_scheduler_type=\"cosine\",\n\n    seed=42,\n\n    load_best_model_at_end=True,\n\n    push_to_hub=True,\n\n)\n\n\n\nparam_to_update = []\n\nfor param in sft_model.parameters():\n\n    if param.requires_grad == True:\n\n        param_to_update.append(param)\n\n\n\noptimizers = AdamW8bit(param_to_update, lr=2e-5)\n\n\n\nmodel_trainer = SFTTrainer(\n\n    model=sft_model,\n\n    tokenizer=sft_tokenizer,\n\n    train_dataset=sft_train_dataset,\n\n    eval_dataset=sft_eval_dataset,\n\n    args=sft_training_args,\n\n    optimizers=(optimizers, None),\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:34:47.705918Z","iopub.execute_input":"2024-11-07T12:34:47.706588Z","iopub.status.idle":"2024-11-07T12:34:48.905148Z","shell.execute_reply.started":"2024-11-07T12:34:47.706538Z","shell.execute_reply":"2024-11-07T12:34:48.904118Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"id":"8bf7e873-c136-4df8-8879-83baccaff44c","cell_type":"code","source":"model_trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:34:58.429237Z","iopub.execute_input":"2024-11-07T12:34:58.430032Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112721144445458, max=1.0â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e2dfc0c9e34716bad4a7cfe6237594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241107_123650-89tf6f4k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sharmaadarsh859-iit-kharagpur/huggingface/runs/89tf6f4k' target=\"_blank\">/content/sample_data</a></strong> to <a href='https://wandb.ai/sharmaadarsh859-iit-kharagpur/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sharmaadarsh859-iit-kharagpur/huggingface' target=\"_blank\">https://wandb.ai/sharmaadarsh859-iit-kharagpur/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sharmaadarsh859-iit-kharagpur/huggingface/runs/89tf6f4k' target=\"_blank\">https://wandb.ai/sharmaadarsh859-iit-kharagpur/huggingface/runs/89tf6f4k</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='281' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [281/625 2:12:37 < 2:43:31, 0.04 it/s, Epoch 2.24/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.418300</td>\n      <td>2.422692</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.298700</td>\n      <td>2.418167</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","output_type":"stream"}],"execution_count":null},{"id":"7bb42546-1e54-4748-a700-234b3fdd85fb","cell_type":"code","source":"rouge_metric = evaluate.load(\"rouge\")\n\ndef compute_metrics(decoded_preds, decoded_actual_labels):\n\n    result = rouge_metric.compute(\n\n        predictions=decoded_preds, references=decoded_actual_labels\n\n    )\n\n    print(f\"SFT Model ROUGE values: {result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:28:56.691261Z","iopub.status.idle":"2024-11-07T12:28:56.691601Z","shell.execute_reply.started":"2024-11-07T12:28:56.691428Z","shell.execute_reply":"2024-11-07T12:28:56.691445Z"}},"outputs":[],"execution_count":null},{"id":"c8172666-bd2e-45ca-8203-e91be5afb4f8","cell_type":"code","source":"generation_kwargs = {\n\n    \"min_length\": -1,  # don't ignore the EOS token\n\n    \"top_k\": 0.0,  # no top-k sampling\n\n    \"top_p\": 1.0,  # no nucleus sampling\n\n    \"do_sample\": True,  # yes, we want to sample\n\n    \"eos_token_id\": sft_tokenizer.eos_token_id,\n\n    \"bos_token_id\": sft_tokenizer.bos_token_id,\n\n    \"pad_token_id\": sft_tokenizer.eos_token_id,  # most decoder models don't have a padding token - use EOS token instead\n\n    \"max_new_tokens\": 32,  # specify how many tokens you want to generate at most\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:28:56.693329Z","iopub.status.idle":"2024-11-07T12:28:56.693813Z","shell.execute_reply.started":"2024-11-07T12:28:56.693561Z","shell.execute_reply":"2024-11-07T12:28:56.693585Z"}},"outputs":[],"execution_count":null},{"id":"091b4b47-3b95-48c8-ab14-b7d80fa0a85c","cell_type":"code","source":"def evaluate_sft_model(sft_model, sft_eval_dataset):\n\n    with torch.no_grad():\n\n        sft_model.eval()\n\n        decoded_preds = []\n\n        decoded_actual_labels = []\n\n        for i in tqdm(range(0, len(sft_eval_dataset[\"input_ids\"]), eval_batch_size)):\n\n            cur_data = torch.tensor(\n\n                sft_eval_dataset[\"input_ids\"][i : i + eval_batch_size]\n\n            )\n\n            cur_preds = sft_model.generate(cur_data, **generation_kwargs)\n\n            cur_preds = cur_preds[:, cur_data.shape[1] :]\n\n            for j in range(eval_batch_size):\n\n                generated_text = sft_tokenizer.decode(\n\n                    cur_preds[j], skip_special_tokens=True\n\n                )\n\n                decoded_preds.append(generated_text)\n\n            cur_actual_label_ids = torch.tensor(\n\n                sft_eval_dataset[\"labels\"][i : i + eval_batch_size]\n\n            )\n\n            for j in range(eval_batch_size):\n\n                decoded_actual_labels.append(\n\n                    sft_tokenizer.decode(\n\n                        cur_actual_label_ids[j], skip_special_tokens=True\n\n                    )\n\n                )\n\n        sft_model_eval_result = compute_metrics(\n\n            decoded_preds=decoded_preds, decoded_actual_labels=decoded_actual_labels\n\n        )\n\n\n\n\n\nevaluate_sft_model(sft_model, sft_eval_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:28:56.694937Z","iopub.status.idle":"2024-11-07T12:28:56.695672Z","shell.execute_reply.started":"2024-11-07T12:28:56.695398Z","shell.execute_reply":"2024-11-07T12:28:56.695426Z"}},"outputs":[],"execution_count":null},{"id":"e07d3860-e6fd-48cb-b638-f5b6dc7055a0","cell_type":"markdown","source":"# Push to hub","metadata":{}},{"id":"e9d0a59d-3b85-43d3-96fa-2ab99be81afa","cell_type":"code","source":"sft_model=sft_model.merge_and_unload()\n\nsft_model.push_to_hub(sft_model_repo_name)\n\nsft_tokenizer.push_to_hub(sft_model_repo_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T12:28:56.697999Z","iopub.status.idle":"2024-11-07T12:28:56.698397Z","shell.execute_reply.started":"2024-11-07T12:28:56.698216Z","shell.execute_reply":"2024-11-07T12:28:56.698235Z"}},"outputs":[],"execution_count":null}]}