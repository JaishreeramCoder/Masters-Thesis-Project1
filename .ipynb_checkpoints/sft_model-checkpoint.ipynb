{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8127b-92f6-419d-a191-c3ef5a3437c8",
   "metadata": {},
   "outputs": [],
   "source": [
    " ! pip install -U bitsandbytes accelerate transformers datasets trl peft evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620109eb-cf11-4114-a94f-2b73badb1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DistilBertTokenizer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import (\n",
    "    SFTTrainer,\n",
    "    PPOTrainer,\n",
    "    RewardTrainer,\n",
    "    PPOConfig,\n",
    "    RewardConfig,\n",
    "    AutoModelForCausalLMWithValueHead,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from bitsandbytes.optim import AdamW8bit\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset as torchDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15447410-a044-42cb-9579-ce07076c1a91",
   "metadata": {},
   "source": [
    "# Hugging face login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1177980-1792-44d3-96b7-370e6e1fbdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bcc2df-99ae-46d8-b033-956f8862ce3e",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dba7a-a06e-427d-a5cc-f296c79d32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n",
    "base_reward_model_checkpoint = \"google/gemma-2-2b\"\n",
    "reward_model_repo_name=\"reward_model\"\n",
    "reward_model_checkpoint=f\"JaishreeramCoder/{reward_model_repo_name}\"\n",
    "output_dir=\"/content/sample_data\"\n",
    "base_sft_model_checkpoint = \"meta-llama/Llama-3.1-8B\"\n",
    "sft_model_repo_name = \"sft_model\"\n",
    "sft_model_checkpoint=f\"JaishreeramCoder/{sft_model_repo_name}\"\n",
    "rlhf_model_repo_name=\"ppo_gpt2_summary\"\n",
    "rlhf_model_checkpoint=f\"JaishreeramCoder/{rlhf_model_repo_name}\"\n",
    "num_train_epochs_reward_model = 5\n",
    "num_train_epochs_sft = 5\n",
    "num_train_epochs_ppo_outer=5\n",
    "ppo_training_batch_size=8\n",
    "eval_batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8225f80-adc8-4805-96be-39d096622a73",
   "metadata": {},
   "source": [
    "# Supervised fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff2eca-e213-4804-b103-97d7804127bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_tokenizer = AutoTokenizer.from_pretrained(base_sft_model_checkpoint)\n",
    "sft_tokenizer.pad_token = sft_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4ec7d-c0b6-43ab-ab06-8d87f57da3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sft_dataset(data):\n",
    "    input_ids, attention_mask, label_ids = ([], [], [])\n",
    "    for i in range(len(data[\"choice\"])):\n",
    "        input = f\"Summarize the following text:\\n\\n{data['info'][i]['post']}\"\n",
    "        cur = sft_tokenizer(\n",
    "            input,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding_side=\"left\",\n",
    "        )\n",
    "        cur_input_ids = cur.input_ids\n",
    "        cur_attention_mask = cur.attention_mask\n",
    "        completion = (\n",
    "            data[\"summaries\"][i][1][\"text\"]\n",
    "            if data[\"choice\"][i] == 1\n",
    "            else data[\"summaries\"][i][0][\"text\"]\n",
    "        )\n",
    "        cur_label_ids = sft_tokenizer(\n",
    "            completion,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding_side=\"left\",\n",
    "        ).input_ids\n",
    "        input_ids.append(cur_input_ids)\n",
    "        attention_mask.append(cur_attention_mask)\n",
    "        label_ids.append(cur_label_ids)\n",
    "\n",
    "    output = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_masks\": attention_mask,\n",
    "        \"labels\": label_ids,\n",
    "    }\n",
    "    output = Dataset.from_dict(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d959b81-f560-4c29-a3da-7322a6d853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_train_dataset = get_sft_dataset(dataset[\"train\"][1000:2000])\n",
    "sft_eval_dataset = get_sft_dataset(dataset[\"validation\"][1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9db73-29bb-4a4c-8c08-39bf22692579",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_sft_model_checkpoint,\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dafc4d-21dd-46f4-8fde-27e130659a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config =  LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "sft_model = get_peft_model(sft_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43159657-c803-4b4b-b4d6-e3f1f480234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_parameters(sft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514baa0-9f39-454b-a350-2aed0ecb7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=num_train_epochs_sft,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=\"/content/sample_data\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "param_to_update = []\n",
    "for param in sft_model.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        param_to_update.append(param)\n",
    "\n",
    "optimizers = AdamW8bit(param_to_update, lr=2e-5)\n",
    "\n",
    "model_trainer = SFTTrainer(\n",
    "    model=sft_model,\n",
    "    tokenizer=sft_tokenizer,\n",
    "    train_dataset=sft_train_dataset,\n",
    "    eval_dataset=sft_eval_dataset,\n",
    "    args=sft_training_args,\n",
    "    optimizers=(optimizers, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7e873-c136-4df8-8879-83baccaff44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb42546-1e54-4748-a700-234b3fdd85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "def compute_metrics(decoded_preds, decoded_actual_labels):\n",
    "    result = rouge_metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_actual_labels\n",
    "    )\n",
    "    print(f\"SFT Model ROUGE values: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8172666-bd2e-45ca-8203-e91be5afb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    \"min_length\": -1,  # don't ignore the EOS token\n",
    "    \"top_k\": 0.0,  # no top-k sampling\n",
    "    \"top_p\": 1.0,  # no nucleus sampling\n",
    "    \"do_sample\": True,  # yes, we want to sample\n",
    "    \"eos_token_id\": sft_tokenizer.eos_token_id,\n",
    "    \"bos_token_id\": sft_tokenizer.bos_token_id,\n",
    "    \"pad_token_id\": sft_tokenizer.eos_token_id,  # most decoder models don't have a padding token - use EOS token instead\n",
    "    \"max_new_tokens\": 32,  # specify how many tokens you want to generate at most\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b4b47-3b95-48c8-ab14-b7d80fa0a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sft_model(sft_model, sft_eval_dataset):\n",
    "    with torch.no_grad():\n",
    "        sft_model.eval()\n",
    "        decoded_preds = []\n",
    "        decoded_actual_labels = []\n",
    "        for i in tqdm(range(0, len(sft_eval_dataset[\"input_ids\"]), eval_batch_size)):\n",
    "            cur_data = torch.tensor(\n",
    "                sft_eval_dataset[\"input_ids\"][i : i + eval_batch_size]\n",
    "            )\n",
    "            cur_preds = sft_model.generate(cur_data, **generation_kwargs)\n",
    "            cur_preds = cur_preds[:, cur_data.shape[1] :]\n",
    "            for j in range(eval_batch_size):\n",
    "                generated_text = sft_tokenizer.decode(\n",
    "                    cur_preds[j], skip_special_tokens=True\n",
    "                )\n",
    "                decoded_preds.append(generated_text)\n",
    "            cur_actual_label_ids = torch.tensor(\n",
    "                sft_eval_dataset[\"labels\"][i : i + eval_batch_size]\n",
    "            )\n",
    "            for j in range(eval_batch_size):\n",
    "                decoded_actual_labels.append(\n",
    "                    sft_tokenizer.decode(\n",
    "                        cur_actual_label_ids[j], skip_special_tokens=True\n",
    "                    )\n",
    "                )\n",
    "        sft_model_eval_result = compute_metrics(\n",
    "            decoded_preds=decoded_preds, decoded_actual_labels=decoded_actual_labels\n",
    "        )\n",
    "\n",
    "\n",
    "evaluate_sft_model(sft_model, sft_eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d3860-e6fd-48cb-b638-f5b6dc7055a0",
   "metadata": {},
   "source": [
    "# Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0a59d-3b85-43d3-96fa-2ab99be81afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_model=sft_model.merge_and_unload()\n",
    "sft_model.push_to_hub(sft_model_repo_name)\n",
    "sft_tokenizer.push_to_hub(sft_model_repo_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
