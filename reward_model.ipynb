{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f20a04-0647-40e2-b788-01f498a23b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:00:43.293896Z",
     "iopub.status.busy": "2024-11-07T11:00:43.293367Z",
     "iopub.status.idle": "2024-11-07T11:01:20.139835Z",
     "shell.execute_reply": "2024-11-07T11:01:20.137403Z",
     "shell.execute_reply.started": "2024-11-07T11:00:43.293831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting trl\n",
      "  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.12.0-py3-none-any.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9a8b4414e46358021d855b3361a0b45cb41f596a54182ceb28786add5f27e6a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score, bitsandbytes, accelerate, transformers, datasets, trl, peft, evaluate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.34.2\n",
      "    Uninstalling accelerate-0.34.2:\n",
      "      Successfully uninstalled accelerate-0.34.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.1\n",
      "    Uninstalling transformers-4.45.1:\n",
      "      Successfully uninstalled transformers-4.45.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.0.1\n",
      "    Uninstalling datasets-3.0.1:\n",
      "      Successfully uninstalled datasets-3.0.1\n",
      "Successfully installed accelerate-1.1.1 bitsandbytes-0.44.1 datasets-3.1.0 evaluate-0.4.3 peft-0.13.2 rouge_score-0.1.2 transformers-4.46.2 trl-0.12.0\n"
     ]
    }
   ],
   "source": [
    " ! pip install -U bitsandbytes accelerate transformers datasets trl peft evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f621824-30a5-4140-a7f4-c213a3cba455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:01:20.146157Z",
     "iopub.status.busy": "2024-11-07T11:01:20.144356Z",
     "iopub.status.idle": "2024-11-07T11:01:42.804199Z",
     "shell.execute_reply": "2024-11-07T11:01:42.803272Z",
     "shell.execute_reply.started": "2024-11-07T11:01:20.146053Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DistilBertTokenizer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import (\n",
    "    SFTTrainer,\n",
    "    PPOTrainer,\n",
    "    RewardTrainer,\n",
    "    PPOConfig,\n",
    "    RewardConfig,\n",
    "    AutoModelForCausalLMWithValueHead,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from bitsandbytes.optim import AdamW8bit\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset as torchDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70cc28b-c45c-4fcb-b0b7-ef588dfca974",
   "metadata": {},
   "source": [
    "# Hugging face login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe21714-1c8a-4f26-a6fa-1c7eedbef890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:03:22.391152Z",
     "iopub.status.busy": "2024-11-07T11:03:22.390662Z",
     "iopub.status.idle": "2024-11-07T11:03:22.645476Z",
     "shell.execute_reply": "2024-11-07T11:03:22.644433Z",
     "shell.execute_reply.started": "2024-11-07T11:03:22.391105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1191e4-3bbc-4da8-acb5-42ba1348ea51",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4482980-a955-4dc9-9af2-48b906b26e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:03:26.675904Z",
     "iopub.status.busy": "2024-11-07T11:03:26.675461Z",
     "iopub.status.idle": "2024-11-07T11:03:27.844883Z",
     "shell.execute_reply": "2024-11-07T11:03:27.844071Z",
     "shell.execute_reply.started": "2024-11-07T11:03:26.675851Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n",
    "base_reward_model_checkpoint = \"google/gemma-2-2b\"\n",
    "reward_model_repo_name=\"reward_model\"\n",
    "output_dir=\"/content/sample_data\"\n",
    "base_sft_model_checkpoint = \"openai-community/gpt2\"\n",
    "sft_model_repo_name = \"sft_gpt2_summary\"\n",
    "sft_model_checkpoint=f\"JaishreeramCoder/{sft_model_repo_name}\"\n",
    "rlhf_model_repo_name=\"ppo_gpt2_summary\"\n",
    "rlhf_model_checkpoint=f\"JaishreeramCoder/{rlhf_model_repo_name}\"\n",
    "num_train_epochs_reward_model = 5\n",
    "num_train_epochs_sft = 5\n",
    "num_train_epochs_ppo_outer=5\n",
    "ppo_training_batch_size=8\n",
    "eval_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc9f6e22-4483-4734-b707-349c986774f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:03:31.531204Z",
     "iopub.status.busy": "2024-11-07T11:03:31.530380Z",
     "iopub.status.idle": "2024-11-07T11:03:31.536824Z",
     "shell.execute_reply": "2024-11-07T11:03:31.535711Z",
     "shell.execute_reply.started": "2024-11-07T11:03:31.531162Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c81dc5-d722-4977-8d45-cc144f9438bf",
   "metadata": {},
   "source": [
    "# Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8220ee76-699f-4fea-9112-8e58e189e5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:03:33.482324Z",
     "iopub.status.busy": "2024-11-07T11:03:33.481871Z",
     "iopub.status.idle": "2024-11-07T11:03:35.305305Z",
     "shell.execute_reply": "2024-11-07T11:03:35.304220Z",
     "shell.execute_reply.started": "2024-11-07T11:03:33.482280Z"
    }
   },
   "outputs": [],
   "source": [
    "reward_tokenizer = AutoTokenizer.from_pretrained(base_reward_model_checkpoint)\n",
    "reward_tokenizer.pad_token = reward_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803c3990-57b8-48fd-9e6d-a4a5bcec519d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:03:36.031735Z",
     "iopub.status.busy": "2024-11-07T11:03:36.031090Z",
     "iopub.status.idle": "2024-11-07T11:03:38.205930Z",
     "shell.execute_reply": "2024-11-07T11:03:38.205048Z",
     "shell.execute_reply.started": "2024-11-07T11:03:36.031696Z"
    }
   },
   "outputs": [],
   "source": [
    "def reward_dataset(data: int):\n",
    "    (\n",
    "        input_ids_chosen,\n",
    "        attention_mask_chosen,\n",
    "        input_ids_rejected,\n",
    "        attention_mask_rejected,\n",
    "    ) = ([], [], [], [])\n",
    "    for i in range(len(data[\"summaries\"])):\n",
    "        if data[\"choice\"] == 0:\n",
    "            chosen = reward_tokenizer(\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "            rejected = reward_tokenizer(\n",
    "                data[\"summaries\"][i][1][\"text\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "        else:\n",
    "            chosen = reward_tokenizer(\n",
    "                data[\"summaries\"][i][1][\"text\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "            rejected = reward_tokenizer(\n",
    "                data[\"summaries\"][i][0][\"text\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "        cur_input_ids_chosen, cur_attention_mask_chosen = (\n",
    "            chosen.input_ids,\n",
    "            chosen.attention_mask,\n",
    "        )\n",
    "        cur_input_ids_rejected, cur_attention_mask_rejected = (\n",
    "            rejected.input_ids,\n",
    "            rejected.attention_mask,\n",
    "        )\n",
    "        input_ids_chosen.append(cur_input_ids_chosen)\n",
    "        attention_mask_chosen.append(cur_attention_mask_chosen)\n",
    "        input_ids_rejected.append(cur_input_ids_rejected)\n",
    "        attention_mask_rejected.append(cur_attention_mask_rejected)\n",
    "        output = {\n",
    "            \"input_ids_chosen\": input_ids_chosen,\n",
    "            \"attention_mask_chosen\": attention_mask_chosen,\n",
    "            \"input_ids_rejected\": input_ids_rejected,\n",
    "            \"attention_mask_rejected\": attention_mask_rejected,\n",
    "        }\n",
    "    return Dataset.from_dict(output)\n",
    "reward_dataset_train = reward_dataset(dataset[\"train\"][0:1000])\n",
    "reward_dataset_eval = reward_dataset(dataset[\"validation\"][0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bb50b3-78ba-4532-9f76-2fc41a857508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:03:45.631579Z",
     "iopub.status.busy": "2024-11-07T11:03:45.631158Z",
     "iopub.status.idle": "2024-11-07T11:08:03.754684Z",
     "shell.execute_reply": "2024-11-07T11:08:03.753825Z",
     "shell.execute_reply.started": "2024-11-07T11:03:45.631541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0a9c19f14a4181a99b6163a1f08daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2864b5bf77f4a24ab32b62b48b6357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f4e6bd9f8c40a9aebf307c99ed5539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f0bd2bd25a476abf0c2be59420f0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0254916561be4f1b82f6fec0020c071b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f647979663a4c7e9f9304f7dcce5e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/481M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b4a2da3c354dbd92023d52252ca435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-2b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_reward_model_checkpoint, num_labels=7, quantization_config=quantization_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81179887-4e14-4d31-af7a-78f3b8b8de35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:08:03.878625Z",
     "iopub.status.busy": "2024-11-07T11:08:03.877760Z",
     "iopub.status.idle": "2024-11-07T11:08:05.069056Z",
     "shell.execute_reply": "2024-11-07T11:08:05.067784Z",
     "shell.execute_reply.started": "2024-11-07T11:08:03.878572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 11:08:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0             31W /  250W |    2595MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cf5fa71-88a7-446d-bf6b-55cbcc868313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:08:05.072231Z",
     "iopub.status.busy": "2024-11-07T11:08:05.071152Z",
     "iopub.status.idle": "2024-11-07T11:08:06.481498Z",
     "shell.execute_reply": "2024-11-07T11:08:06.480412Z",
     "shell.execute_reply.started": "2024-11-07T11:08:05.072170Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_config =  LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "reward_model = get_peft_model(reward_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64ae15e9-746c-4167-be37-573e660e61f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:08:06.485289Z",
     "iopub.status.busy": "2024-11-07T11:08:06.484667Z",
     "iopub.status.idle": "2024-11-07T11:08:06.499693Z",
     "shell.execute_reply": "2024-11-07T11:08:06.498524Z",
     "shell.execute_reply.started": "2024-11-07T11:08:06.485239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1614999552, 12779520)\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(reward_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177aed3b-6fa8-48de-aa6d-d1891078e545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:08:06.501618Z",
     "iopub.status.busy": "2024-11-07T11:08:06.501226Z",
     "iopub.status.idle": "2024-11-07T11:08:07.670627Z",
     "shell.execute_reply": "2024-11-07T11:08:07.669430Z",
     "shell.execute_reply.started": "2024-11-07T11:08:06.501579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 11:08:07 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0             31W /  250W |    2647MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e1cece1-1fd3-42a4-9fec-61f2e29156c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T11:08:07.672811Z",
     "iopub.status.busy": "2024-11-07T11:08:07.672425Z",
     "iopub.status.idle": "2024-11-07T13:25:53.956976Z",
     "shell.execute_reply": "2024-11-07T13:25:53.956071Z",
     "shell.execute_reply.started": "2024-11-07T11:08:07.672771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd947ca41f74f4d83a2b6651e749175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113442477780053, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241107_111200-staunkuu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sharmaadarsh345678-iit-kharagpur/huggingface/runs/staunkuu' target=\"_blank\">/content/sample_data</a></strong> to <a href='https://wandb.ai/sharmaadarsh345678-iit-kharagpur/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sharmaadarsh345678-iit-kharagpur/huggingface' target=\"_blank\">https://wandb.ai/sharmaadarsh345678-iit-kharagpur/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sharmaadarsh345678-iit-kharagpur/huggingface/runs/staunkuu' target=\"_blank\">https://wandb.ai/sharmaadarsh345678-iit-kharagpur/huggingface/runs/staunkuu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 2:13:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.919900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=625, training_loss=0.88238310546875, metrics={'train_runtime': 8264.7764, 'train_samples_per_second': 0.605, 'train_steps_per_second': 0.076, 'total_flos': 0.0, 'train_loss': 0.88238310546875, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model_param_to_update = []\n",
    "for param in reward_model.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        reward_model_param_to_update.append(param)\n",
    "optimizers = AdamW8bit(reward_model_param_to_update, lr=2e-5)\n",
    "reward_training_args = RewardConfig(\n",
    "    output_dir=output_dir,\n",
    "    max_length=512,\n",
    "    num_train_epochs=num_train_epochs_reward_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    ")\n",
    "reward_trainer = RewardTrainer(\n",
    "    args=reward_training_args,\n",
    "    train_dataset=reward_dataset_train,\n",
    "    model=reward_model,\n",
    "    tokenizer=reward_tokenizer,\n",
    "    optimizers=(optimizers, None),\n",
    ")\n",
    "reward_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e9bf2-96e2-4986-9ebd-abb40c095c08",
   "metadata": {},
   "source": [
    "# Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d13ef6d7-045d-47f4-8788-5eca8b8e9489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T13:50:02.262082Z",
     "iopub.status.busy": "2024-11-07T13:50:02.261701Z",
     "iopub.status.idle": "2024-11-07T13:51:19.236900Z",
     "shell.execute_reply": "2024-11-07T13:51:19.235914Z",
     "shell.execute_reply.started": "2024-11-07T13:50:02.262049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ce08b025ee4fc583efd6468121955c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33340b43e3024d2e8604846a7ef01074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ee4c5359834737997ef5665a71ca17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968020a0e77b4fe1bc66f014afd0d2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c27a24864e496e9e7d94806f4bbd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/JaishreeramCoder/reward_model/commit/f4064b0d01e75e079d931f46d79ba94f09e59cfc', commit_message='Upload tokenizer', commit_description='', oid='f4064b0d01e75e079d931f46d79ba94f09e59cfc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/JaishreeramCoder/reward_model', endpoint='https://huggingface.co', repo_type='model', repo_id='JaishreeramCoder/reward_model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reward_model=reward_model.merge_and_unload()\n",
    "\n",
    "reward_model.push_to_hub(reward_model_repo_name)\n",
    "\n",
    "reward_tokenizer.push_to_hub(reward_model_repo_name)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
